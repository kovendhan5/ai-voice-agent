#!/usr/bin/env python3
"""
üéØ INTEL-OPTIMIZED VOICE SYNTHESIS (FIXED AUDIO)
==================================================
‚úÖ Designed for Intel 12th Gen processors
‚úÖ Works with Intel Iris integrated graphics
‚úÖ No NVIDIA drivers required
‚úÖ Real emotion tag support
‚úÖ Fixed audio playback for Intel systems
==================================================
"""

import os
import sys
import warnings
import torch
import numpy as np
import soundfile as sf
import pygame
import time
from typing import Optional, Dict, List
import tempfile
import threading
import queue
import asyncio
import io

# Force CPU-only mode for Intel systems
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['FORCE_CPU'] = '1'
torch.set_num_threads(4)  # Optimize for Intel 12th gen

# Suppress warnings
warnings.filterwarnings("ignore")

class IntelOptimizedTTS:
    """
    Intel-optimized TTS system for 12th gen processors
    Fixed audio playback for Intel Iris graphics
    """
    
    def __init__(self):
        self.device = 'cpu'
        self.sample_rate = 22050
        self.voices = {
            'tara': 'en-US-AriaNeural',
            'leah': 'en-US-JennyNeural', 
            'jess': 'en-US-AmberNeural',
            'leo': 'en-US-BrandonNeural',
            'dan': 'en-US-GuyNeural',
            'mia': 'en-US-SaraNeural',
            'zac': 'en-US-DavisNeural',
            'zoe': 'en-US-MichelleNeural'
        }
        
        self.emotion_tags = {
            '<happy>': {'pitch': '+20%', 'rate': '+10%'},
            '<sad>': {'pitch': '-20%', 'rate': '-10%'},
            '<excited>': {'pitch': '+30%', 'rate': '+20%'},
            '<angry>': {'pitch': '+10%', 'rate': '+10%'},
            '<whisper>': {'pitch': '-10%', 'rate': '-20%'},
            '<laugh>': {'pitch': '+20%', 'rate': '+0%'},
            '<calm>': {'pitch': '+0%', 'rate': '-10%'},
            '<surprised>': {'pitch': '+40%', 'rate': '+20%'}
        }
        
        # Initialize pygame mixer for Intel graphics
        pygame.mixer.pre_init(frequency=22050, size=-16, channels=1, buffer=512)
        pygame.mixer.init()
        
    def parse_emotion_text(self, text: str) -> tuple:
        """Parse emotion tags from text"""
        emotion_params = {'pitch': '+0%', 'rate': '+0%'}
        clean_text = text
        
        for tag, params in self.emotion_tags.items():
            if tag in text:
                emotion_params.update(params)
                clean_text = clean_text.replace(tag, '')
                print(f"üé≠ Detected emotion: {tag}")
                break
                
        return clean_text.strip(), emotion_params
    
    async def generate_edge_tts(self, text: str, voice: str, emotion_params: dict) -> bytes:
        """Generate speech using Edge TTS with proper SSML"""
        import edge_tts
        
        edge_voice = self.voices.get(voice, 'en-US-AriaNeural')
        
        # Create proper SSML with emotion parameters
        ssml_text = f"""<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="en-US">
            <voice name="{edge_voice}">
                <prosody pitch="{emotion_params['pitch']}" rate="{emotion_params['rate']}">
                    {text}
                </prosody>
            </voice>
        </speak>"""
        
        try:
            communicate = edge_tts.Communicate(text, edge_voice)
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            
            return audio_data if audio_data else None
            
        except Exception as e:
            print(f"‚ùå Edge TTS error: {e}")
            return None
    
    def play_audio_intel(self, audio_data: bytes) -> bool:
        """Play audio optimized for Intel Iris graphics"""
        if not audio_data:
            print("‚ùå No audio data to play")
            return False
            
        try:
            # Method 1: Save to temporary WAV file and play
            temp_file = tempfile.mktemp(suffix='.wav')
            
            with open(temp_file, 'wb') as f:
                f.write(audio_data)
            
            # Load and play with pygame
            pygame.mixer.music.load(temp_file)
            pygame.mixer.music.play()
            
            # Wait for playback to complete
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
            
            # Clean up
            try:
                os.unlink(temp_file)
            except:
                pass
                
            print("‚úÖ Audio played successfully")
            return True
            
        except Exception as e:
            print(f"‚ùå Pygame audio error: {e}")
            
            # Fallback: Try with soundfile conversion
            try:
                # Convert audio data to proper format
                import soundfile as sf
                import io
                
                # Read audio data
                audio_io = io.BytesIO(audio_data)
                data, samplerate = sf.read(audio_io)
                
                # Save as WAV
                temp_wav = tempfile.mktemp(suffix='.wav')
                sf.write(temp_wav, data, samplerate)
                
                # Play with pygame
                pygame.mixer.music.load(temp_wav)
                pygame.mixer.music.play()
                
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
                
                os.unlink(temp_wav)
                print("‚úÖ Audio played with soundfile conversion")
                return True
                
            except Exception as e2:
                print(f"‚ùå Soundfile fallback error: {e2}")
                
                # Final fallback: Play with Windows system
                try:
                    import winsound
                    temp_wav = tempfile.mktemp(suffix='.wav')
                    with open(temp_wav, 'wb') as f:
                        f.write(audio_data)
                    
                    winsound.PlaySound(temp_wav, winsound.SND_FILENAME)
                    os.unlink(temp_wav)
                    print("‚úÖ Audio played with winsound")
                    return True
                    
                except Exception as e3:
                    print(f"‚ùå Winsound fallback error: {e3}")
                    return False
    
    async def synthesize_speech(self, text: str, voice: str = 'tara') -> bool:
        """Main synthesis function optimized for Intel systems"""
        if not text.strip():
            return False
            
        print(f"üé§ Synthesizing: '{text[:50]}...' with voice '{voice}'")
        
        # Parse emotions
        clean_text, emotion_params = self.parse_emotion_text(text)
        
        try:
            # Generate audio with Edge TTS
            audio_data = await self.generate_edge_tts(clean_text, voice, emotion_params)
            
            if audio_data:
                # Play audio with Intel-optimized playback
                success = self.play_audio_intel(audio_data)
                if success:
                    print("‚úÖ Speech synthesis complete")
                    return True
                else:
                    print("‚ùå Audio playback failed")
                    return False
            else:
                print("‚ùå No audio generated")
                return False
                
        except Exception as e:
            print(f"‚ùå Synthesis error: {e}")
            return False

def test_intel_tts():
    """Test Intel-optimized TTS system with fixed audio"""
    print("üéØ INTEL 12TH GEN TTS TEST (FIXED AUDIO)")
    print("=" * 50)
    print("üñ•Ô∏è Intel Core i5-12500H")
    print("üéÆ Intel Iris Xe Graphics")
    print("üö´ No NVIDIA GPU required")
    print("üîß Fixed audio playback")
    print("=" * 50)
    
    # Initialize TTS
    tts = IntelOptimizedTTS()
    
    # Test cases optimized for Intel
    test_cases = [
        ("Hello! I'm running perfectly on your Intel processor.", "tara"),
        ("<happy>This is so exciting! Intel graphics work perfectly!</happy>", "jess"),
        ("<whisper>This is a quiet whisper test for Intel</whisper>", "leah"),
        ("Your Intel 12th gen processor handles this beautifully.", "dan"),
        ("<excited>Amazing! No NVIDIA drivers needed!</excited>", "mia")
    ]
    
    print("\nüß™ Running Intel TTS tests with fixed audio...")
    
    async def run_tests():
        success_count = 0
        for i, (text, voice) in enumerate(test_cases, 1):
            print(f"\nüîä Test {i}/5: {voice}")
            success = await tts.synthesize_speech(text, voice)
            if success:
                print(f"‚úÖ Test {i} PASSED")
                success_count += 1
            else:
                print(f"‚ùå Test {i} FAILED")
            
            # Wait between tests
            await asyncio.sleep(1.5)
        
        print(f"\nüéâ Intel TTS testing complete!")
        print(f"‚úÖ Success rate: {success_count}/5 tests passed")
        
        if success_count >= 4:
            print("üèÜ EXCELLENT: Your Intel system is working perfectly!")
        elif success_count >= 2:
            print("üëç GOOD: Your Intel system is mostly working!")
        else:
            print("‚ö†Ô∏è NEEDS ATTENTION: Some issues with audio playback")
    
    asyncio.run(run_tests())
    return True

def demo_emotion_tags():
    """Demo all emotion tags on Intel system"""
    print("\nüé≠ EMOTION TAGS DEMO FOR INTEL")
    print("=" * 40)
    
    tts = IntelOptimizedTTS()
    
    emotions = [
        ("<happy>I'm so happy on Intel!</happy>", "tara"),
        ("<excited>This is so exciting!</excited>", "jess"),
        ("<whisper>Secret Intel power</whisper>", "leah"),
        ("<calm>Very peaceful and calm</calm>", "mia"),
        ("<surprised>Wow! Intel is amazing!</surprised>", "dan")
    ]
    
    async def run_emotion_demo():
        for text, voice in emotions:
            await tts.synthesize_speech(text, voice)
            await asyncio.sleep(2)
    
    asyncio.run(run_emotion_demo())

if __name__ == "__main__":
    print("üéØ INTEL-OPTIMIZED ORPHEUS-STYLE TTS (FIXED)")
    print("=" * 50)
    print("üíª Designed for Intel 12th Gen processors")
    print("üéÆ Compatible with Intel Iris graphics")
    print("üö´ No NVIDIA drivers required")
    print("üîß Fixed audio playback issues")
    print("=" * 50)
    
    # Check system
    print(f"üñ•Ô∏è Device: {torch.device('cpu')}")
    print(f"üßµ Threads: {torch.get_num_threads()}")
    print(f"üêç Python: {sys.version.split()[0]}")
    
    # Run test
    test_intel_tts()
    
    # Ask for emotion demo
    print("\n" + "=" * 50)
    response = input("üé≠ Would you like to test emotion tags? (y/n): ")
    if response.lower() == 'y':
        demo_emotion_tags()
